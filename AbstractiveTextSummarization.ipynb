{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AbstractiveTextSummarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk69dG5w147Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import __version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azvhL1Sx1_rs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bc918bfb-9c1d-448c-eb24-04765d365859"
      },
      "source": [
        "__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i271Db-92BBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WNlVVgt2D00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oo=pd.read_csv('sampled_reviews.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr0fRc1X1qpN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "df7ff9d6-059a-454d-d24c-72886ce59ec7"
      },
      "source": [
        "oo.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>cleaned_summary</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>178885</td>\n",
              "      <td>178892</td>\n",
              "      <td>good sweetener</td>\n",
              "      <td>is very good for all it does not contain any s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>240275</td>\n",
              "      <td>240285</td>\n",
              "      <td>smiley likes it</td>\n",
              "      <td>while our dog smiley will eat just about anyth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>298013</td>\n",
              "      <td>298024</td>\n",
              "      <td>high on low on flavor</td>\n",
              "      <td>if you want to eat a lot for only a few calori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>538510</td>\n",
              "      <td>538537</td>\n",
              "      <td>death rain this name says it</td>\n",
              "      <td>the first time i tried these was from the vend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>200181</td>\n",
              "      <td>200189</td>\n",
              "      <td>post selects banana nut crunch cereal review</td>\n",
              "      <td>great grains banana nut crunch cereal is reall...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                       cleaned_text\n",
              "0      178885  ...  is very good for all it does not contain any s...\n",
              "1      240275  ...  while our dog smiley will eat just about anyth...\n",
              "2      298013  ...  if you want to eat a lot for only a few calori...\n",
              "3      538510  ...  the first time i tried these was from the vend...\n",
              "4      200181  ...  great grains banana nut crunch cereal is reall...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPGolihf8Npk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oo=oo.drop(labels=['Unnamed: 0','Unnamed: 0.1'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok9UaGMA8YtB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "3dd71625-e370-49d1-b4c8-2c5139324b62"
      },
      "source": [
        "oo.sample(4)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_summary</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13658</th>\n",
              "      <td>dilution required mixing required</td>\n",
              "      <td>the directions on the bottle state that one sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1861</th>\n",
              "      <td>quick morning brew</td>\n",
              "      <td>been drinking one or two cups of senseo medium...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7637</th>\n",
              "      <td>earl grey still a winner</td>\n",
              "      <td>the flavor is good but not as robust as it wou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1109</th>\n",
              "      <td>not</td>\n",
              "      <td>acai in my book is over we no longer drink the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         cleaned_summary                                       cleaned_text\n",
              "13658  dilution required mixing required  the directions on the bottle state that one sh...\n",
              "1861                  quick morning brew  been drinking one or two cups of senseo medium...\n",
              "7637            earl grey still a winner  the flavor is good but not as robust as it wou...\n",
              "1109                                 not  acai in my book is over we no longer drink the..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Cfj5148Z-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9905cd5b-8c50-4566-fbf9-c3759a891722"
      },
      "source": [
        "'''\n",
        "MY UNDERSTANDING OF ENCODER-DECODER MODELS\n",
        "\n",
        "For text sumnmarization we're going to use a sequence to sequence encoder-decoder architecture\n",
        "as it is ideal for solving problems where the input and output are of different lengths.\n",
        "\n",
        "An encoder decoder architecture has two phases:\n",
        "\n",
        "1) Training Phase: The encoder lstm reads the entire input sequence where at each timestep we are \n",
        "                   feeding one word at a time into the encoder.\n",
        "                   The encoder will capture the context from these input sequences.\n",
        "                   The so called \"context\" would be the last hidden state and cell state produced by the encoder\n",
        "                   after capturing context from the input sequence.\n",
        "\n",
        "                   The decoder takes a target sequence and encoder hidden and cell states as input and predict the \n",
        "                   target sequence incremented by one time step.\n",
        "                   \n",
        "                   The decoder can take the context of \"Oh my God I hate this coffee!\" from the encoder\n",
        "                   and the word \"hate\" and predict the word \"coffee\". That's what the decoder is being trained for.\n",
        "\n",
        "                   A <start> token has to be added to a decoder's input sequence so as to be able to be able to predict\n",
        "                   the first word of the decoder output sequence using the combination of the <start> token and the context\n",
        "                   coming in from the encoder. The decoder can take the context from \"Oh my god, I hate this cofee\" and the\n",
        "                   <start> token and predict the first word of the target which would be a summary in our case which would be\n",
        "                   \"hate\".\n",
        "\n",
        "                   The <stop> token has to be added to the target sequence so that a decoder can predict the end of a sentence\n",
        "                   given the context from an encoder and the last word from the target sequence. So given the context from \n",
        "                   \"Oh my God, I hate this coffee\" and \"coffee\" and predict the <stop> token.\n",
        "\n",
        "2) Inference Phase: Once we have our encoder trained to convert input sequence and convert it to a context and a decoder\n",
        "                    that can take that context and some word from a target sequence and predict the next word we use the model\n",
        "                    to start generating target sequence.\n",
        "\n",
        "                    1)Encode entire input sequence and intialize decoder with the states returned from the encoder\n",
        "                    2)Pass the <start> as input into the decoder.\n",
        "                    3)Run the decoder for one time step. The output will be the probabilities for the next word\n",
        "                      and the word with the highest probability will be selected.\n",
        "                    4)Next, this high probability selected word will be passed into the decoder, which will update the \n",
        "                      the states of the decoder which will predict the next word\n",
        "                    5)This process of passing the word again and again by passing it into the decoder and updating states at each output\n",
        "                      will continue till either a <stop> token is predicted or the length of the predicted sequence that you've been \n",
        "                      accumulating is equal to the maximum length of any target sequence in the training dataset.\n",
        "'''\n",
        "print('this is here to list my assumptions and to debug any errors I get during programming the model.')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is here to list my assumptions and to debug any errors I get during programming the model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4ljWRpbQE-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oo['target_summary']=oo.cleaned_summary.apply(lambda text: \"<START> \"+str(text)+\" <STOP>\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pljFxBDCQnIi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "3dad27c3-4a2a-4d46-852f-6413a2ee2069"
      },
      "source": [
        "oo.head(1)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_summary</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>target_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good sweetener</td>\n",
              "      <td>is very good for all it does not contain any s...</td>\n",
              "      <td>&lt;START&gt; good sweetener &lt;STOP&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  cleaned_summary  ...                 target_summary\n",
              "0  good sweetener  ...  <START> good sweetener <STOP>\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGOHdRq_HfQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oo=oo[oo.cleaned_text.str.len()<= 500]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UL6M0XzHvZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "893de1ab-ae95-4aaf-c1c2-f30f176a9a11"
      },
      "source": [
        "oo.sample(3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_summary</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>target_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5706</th>\n",
              "      <td>these are</td>\n",
              "      <td>i keep them in my drawer at work for snacking ...</td>\n",
              "      <td>&lt;START&gt; these are &lt;STOP&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10547</th>\n",
              "      <td>very cherry</td>\n",
              "      <td>just what i not too not to as the ones in the ...</td>\n",
              "      <td>&lt;START&gt; very cherry &lt;STOP&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2662</th>\n",
              "      <td>uneven production quality</td>\n",
              "      <td>i have purchased a carton containing least hal...</td>\n",
              "      <td>&lt;START&gt; uneven production quality &lt;STOP&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 cleaned_summary  ...                            target_summary\n",
              "5706                   these are  ...                  <START> these are <STOP>\n",
              "10547                very cherry  ...                <START> very cherry <STOP>\n",
              "2662   uneven production quality  ...  <START> uneven production quality <STOP>\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_ciS4_JHvlf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "dc1afaa7-048b-403f-9b2d-3c1047231156"
      },
      "source": [
        "oo.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11533, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuufCkErCQzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_maxlen=max([len(s) for s in oo.cleaned_text])\n",
        "y_maxlen=max([len(s) for s in oo.target_summary])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNhmGt3uH78s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0523b061-74d9-4178-e2e3-8b6a409e186e"
      },
      "source": [
        "x_maxlen"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeCjgTlOETXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_words=set()\n",
        "\n",
        "for seq in oo.cleaned_text:\n",
        "  for word in seq.split(' '):\n",
        "    if word not in unique_words:\n",
        "      unique_words.add(word)\n",
        "for seq in oo.target_summary:\n",
        "  for word in seq.split(' '):\n",
        "    if word not in unique_words:\n",
        "      unique_words.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIkNQQ4_F0mK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_words=list(unique_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0oY7wKKF5th",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index={value:index for index,value in enumerate(unique_words)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U9uGiprGC2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_word_index={value:key for key,value in word_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv2BrhEZGXz9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c5b397d2-391e-440e-b0e6-1cb3e2694149"
      },
      "source": [
        "oo.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11533, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzqNy1WAHMkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "x_tokenizer=Tokenizer()\n",
        "x_tokenizer.fit_on_texts(oo.cleaned_text)\n",
        "X=x_tokenizer.texts_to_sequences(oo.cleaned_text)\n",
        "X=pad_sequences(X,maxlen=x_maxlen,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZXp9xcEGEN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_tokenizer=Tokenizer()\n",
        "y_tokenizer.fit_on_texts(oo.target_summary)\n",
        "y=y_tokenizer.texts_to_sequences(oo.target_summary)\n",
        "y=pad_sequences(y,maxlen=y_maxlen,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcB3oMP2JKp3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "616b3178-2136-4cce-c774-e9c8ef4e65bf"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11533, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QWsaRueJLzx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "93176c5e-bc4b-476f-b849-fc5a3ae86e19"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11533, 117)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95yruJvaJNZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_vocab_size=len(x_tokenizer.word_index)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atJTNUYoJg61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_vocab_size=len(y_tokenizer.word_index)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQYt_DsdJnBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB1p-no-Jvft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Dense, LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyecdaQRJ_-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim=256\n",
        "encoder_input=Input(shape=(x_maxlen,),name='encoder_input')\n",
        "enc_embedding_layer=Embedding(x_vocab_size,latent_dim,trainable=True,name='encoder_embedding')\n",
        "enc_embedding=enc_embedding_layer(encoder_input)\n",
        "\n",
        "encoder_lstm1=LSTM(latent_dim,return_state=True,name='encoder_lstm')\n",
        "encoder_output1,state_h,state_c=encoder_lstm1(enc_embedding)\n",
        "\n",
        "encoder_states=[state_h,state_c]\n",
        "\n",
        "decoder_input=Input(shape=(None,),name='decoder_input')# try changing to None\n",
        "decoder_embedding_layer=Embedding(y_vocab_size,latent_dim,trainable=True,name='decoder_embedding')\n",
        "decoder_embedding=decoder_embedding_layer(decoder_input)\n",
        "\n",
        "decoder_lstm=LSTM(latent_dim,return_sequences=True,return_state=True,name='decoder_lstm')\n",
        "decoder_output, _, _=decoder_lstm(decoder_embedding,initial_state=encoder_states)\n",
        "\n",
        "decoder_dense=Dense(y_vocab_size,activation='softmax')\n",
        "decoder_output=decoder_dense(decoder_output)\n",
        "\n",
        "model=Model([encoder_input,decoder_input],decoder_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMrgGuUjO-Kt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "ba9b6cf3-dc76-41a7-e00e-a49c3c140e32"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_embedding (Embedding)   (None, 500, 256)     3477248     encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_embedding (Embedding)   (None, None, 256)    1126912     decoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm (LSTM)             [(None, 256), (None, 525312      encoder_embedding[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm (LSTM)             [(None, None, 256),  525312      decoder_embedding[0][0]          \n",
            "                                                                 encoder_lstm[0][1]               \n",
            "                                                                 encoder_lstm[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, None, 4402)   1131314     decoder_lstm[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 6,786,098\n",
            "Trainable params: 6,786,098\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz4dPvl0PAmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ire_LH0Pu8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "18c0352f-08a4-4e89-c3e7-664c5a9bb256"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11533, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5jgY3FiPzyp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bcf49160-ed6d-45d7-c5eb-96c1eb897289"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11533, 117)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL8KnYg5P1mY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgRHClnYQAsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiYMyaJfQLTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "a9a35b21-e59f-4d54-df00-e591f32cb272"
      },
      "source": [
        "history=model.fit([X_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,epochs=10,validation_split=0.1)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7784 samples, validate on 865 samples\n",
            "Epoch 1/10\n",
            "7784/7784 [==============================] - 1122s 144ms/sample - loss: 0.1903 - accuracy: 0.9729 - val_loss: 0.1891 - val_accuracy: 0.9724\n",
            "Epoch 2/10\n",
            "7784/7784 [==============================] - 1130s 145ms/sample - loss: 0.1847 - accuracy: 0.9729 - val_loss: 0.1866 - val_accuracy: 0.9727\n",
            "Epoch 3/10\n",
            "7784/7784 [==============================] - 1135s 146ms/sample - loss: 0.1810 - accuracy: 0.9731 - val_loss: 0.1855 - val_accuracy: 0.9729\n",
            "Epoch 4/10\n",
            "7784/7784 [==============================] - 1150s 148ms/sample - loss: 0.1771 - accuracy: 0.9733 - val_loss: 0.1817 - val_accuracy: 0.9731\n",
            "Epoch 5/10\n",
            "7784/7784 [==============================] - 1140s 146ms/sample - loss: 0.1730 - accuracy: 0.9735 - val_loss: 0.1801 - val_accuracy: 0.9734\n",
            "Epoch 6/10\n",
            "7784/7784 [==============================] - 1132s 145ms/sample - loss: 0.1692 - accuracy: 0.9738 - val_loss: 0.1790 - val_accuracy: 0.9734\n",
            "Epoch 7/10\n",
            "7784/7784 [==============================] - 1152s 148ms/sample - loss: 0.1661 - accuracy: 0.9740 - val_loss: 0.1772 - val_accuracy: 0.9735\n",
            "Epoch 8/10\n",
            "7784/7784 [==============================] - 1165s 150ms/sample - loss: 0.1631 - accuracy: 0.9742 - val_loss: 0.1778 - val_accuracy: 0.9735\n",
            "Epoch 9/10\n",
            "7784/7784 [==============================] - 1131s 145ms/sample - loss: 0.1601 - accuracy: 0.9744 - val_loss: 0.1768 - val_accuracy: 0.9736\n",
            "Epoch 10/10\n",
            "7784/7784 [==============================] - 1151s 148ms/sample - loss: 0.1574 - accuracy: 0.9746 - val_loss: 0.1772 - val_accuracy: 0.9728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqsTPoGeRZ_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('summarizer.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsg9x_drkQpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_input_data=y_train[:,:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1NXuhzUFen_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6f4796d6-5c5c-4fb5-f3b2-e3b6656c740f"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8649, 117)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWiAKO0jFg9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "57b543bc-f418-4a03-981d-0641b145a8ef"
      },
      "source": [
        "decoder_input_data.shape"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8649, 116)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V3ukezNJQgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "347fb0ad-06f1-4890-d80e-3b538fb5f096"
      },
      "source": [
        "decoder_target_data.shape"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8649, 116, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6YSctH8JR9L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "fba0a1fd-8e8f-447a-c901-776fa454d213"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8649, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB5F6tXkJYG4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "outputId": "429eeb6f-634e-42e8-a200-8a8da6967b39"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2,   52,   73,  153,    4,  207,   51,  289,  472,   41,  191,\n",
              "        375,  319,    2,   97,    8,    2,  187,    1,  123, 1018,  600,\n",
              "          5,  600,    3,  174,    4,   38, 1662,    9,    1,  880,  285,\n",
              "          8,   48,    7,   67, 2271,   11,  472,   54,   49,    1,   51,\n",
              "        289,   78,  274,    2,   70,    4,  198,  364,    3,   42,  460,\n",
              "          5,   62,    8,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg9yFxoTKDFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "d5c196a2-edf9-4b85-815c-10e8fcec343b"
      },
      "source": [
        "decoder_input_data[0]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2, 22,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1inn9KDKE5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "375b2368-7b22-4b5a-e344-177ba6e90903"
      },
      "source": [
        "decoder_target_data[0]"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22],\n",
              "       [ 1],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWCzqNHiKIPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Inference Phase\n",
        "encoder_model=Model(inputs=encoder_input,outputs=[encoder_output1,state_h,state_c])\n",
        "#this model uses the trained encoder layer to encode complete input sequences\n",
        "\n",
        "decoder_state_input_h=Input(shape=(latent_dim,))\n",
        "decoder_state_input_c=Input(shape=(latent_dim,))#shape should match the number of units in the decoder LSTM cell.\n",
        "#decoder_hidden_state_input=Input(shape=(x_maxlen,latent_dim))\n",
        "\n",
        "decoder_embedding_2=decoder_embedding_layer(decoder_input)\n",
        "decoder_states_inputs=[decoder_state_input_h,decoder_state_input_c]\n",
        "\n",
        "decoder_output_2,state_h2,state_c2=decoder_lstm(decoder_embedding_2,initial_state=decoder_states_inputs)\n",
        "\n",
        "decoder_states=[state_h2,state_c2]\n",
        "\n",
        "decoder_output_2=decoder_dense(decoder_output_2)\n",
        "\n",
        "decoder_model=Model([decoder_input]+decoder_states_inputs,\n",
        "                    [decoder_output_2]+decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zie3VuPQ-Sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_word_index=y_tokenizer.word_index\n",
        "input_word_index=x_tokenizer.word_index\n",
        "\n",
        "reverse_target_word_index={value:key for key,value in target_word_index.items()}\n",
        "reverse_input_word_index={value:key for key,value in input_word_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNRnaJwoRkSj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "69cb2648-ac45-4da3-ff32-51d7e5cb370e"
      },
      "source": [
        "target_word_index['start']"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL5a7nXqPmKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  encoder_out, encoder_h, encoder_c= encoder_model.predict(input_seq)\n",
        "\n",
        "  target_seq=np.zeros((1,1))\n",
        "\n",
        "  target_seq[0,0]=target_word_index['start']\n",
        "\n",
        "  stop_condition=False\n",
        "  decoded_sentence=''\n",
        "\n",
        "  while not stop_condition:\n",
        "    output_tokens, h, c= decoder_model.predict([target_seq]+[encoder_out,encoder_h,encoder_c])\n",
        "\n",
        "    sampled_token_index=np.argmax(output_tokens[0, -1,:])\n",
        "    sampled_token=reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "    if sampled_token != 'stop':\n",
        "      decoded_sentence+=' '+sampled_token\n",
        "    else:\n",
        "      stop_condition=True\n",
        "\n",
        "    if len(decoded_sentence) >= (y_maxlen-1):\n",
        "        stop_condition=True\n",
        "    \n",
        "    target_seq=np.zeros((1,1))\n",
        "    target_seq[0,0] = sampled_token_index\n",
        "\n",
        "    encoder_h, encoder_c = h, c\n",
        "  \n",
        "  return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riQtXdAuYObC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if(sampled_token!='stop'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "            if (sampled_token == 'stop' or len(decoded_sentence.split()) >= (y_maxlen-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT5_ONwgUZoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['stop']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_input_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z4WxOgdVTax",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5c5883b1-0843-4fdc-ca49-d9548b584aed"
      },
      "source": [
        "import numpy as np\n",
        "for i in range(len(X_train)):\n",
        "  print(\"Review:\",seq2text(X_test[i]))\n",
        "  print(\"Original summary:\",seq2summary(y_test[i]))\n",
        "  print(\"Predicted summary:\",decode_sequence(X_test[i].reshape(1,x_maxlen)))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: my dog has developed bad allergies later when he was years naturally tried several premium dog food and feeding special formula foods are the only kind i found that my skin he was on the fish formula for over a but after a while it started to trigger his lately i feed him with the potato duck so far works really his fur is perfectly healthy and \n",
            "Original summary: good quality food for special needs dog \n",
            "Predicted summary:  nan nasty expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected\n",
            "\n",
            "\n",
            "Review: i would highly recommend these in place of fruit rolls ups or other gummy fruit snacks that are full of these are all no added sugar and have a i like them as much as my walmart used to carry i requested that they continue stocking them but have not had any so i have to purchase them from a bit expensive but delicious and \n",
            "Original summary: delicious and no added \n",
            "Predicted summary:  nan nasty expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected\n",
            "\n",
            "\n",
            "Review: this product is very good for my dog and he sits at the pantry door looking forward to it more times a day than is really loves also has cookies from the \n",
            "Original summary: hip bones \n",
            "Predicted summary:  nan nasty expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected\n",
            "\n",
            "\n",
            "Review: tasteful small item to express thanks to a person who showed you a clerk who treated you with expected respect and a wait staff person who recognizes repeat customers and utter those words no problem just enjoy them \n",
            "Original summary: nice little thank you \n",
            "Predicted summary:  nan nasty expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected\n",
            "\n",
            "\n",
            "Review: great best price fast order on continuing read reviews where people thought this was get it they must like brown water not \n",
            "Original summary: my favorite for the \n",
            "Predicted summary:  nan nasty expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected\n",
            "\n",
            "\n",
            "Review: i am somewhat of a mac and cheese this stuff is i like the fact that whole \n",
            "Original summary: nan \n",
            "Predicted summary:  nan nasty expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected\n",
            "\n",
            "\n",
            "Review: they were like all mini reeses for the price paid this bag is i found the same bag the next day for about a gallon candy jar half way in penny candy or gallon heritage \n",
            "Original summary: rip off \n",
            "Predicted summary:  nan nasty expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected expected\n",
            "\n",
            "\n",
            "Review: i remember about years ago my brother in law my came home from a trip with his he brought over a lb box of this funny broken up bits of dusted in powdered sugar and crushed i grabbed a small piece and popped it in my at that point and time i heard the sound of singing cherubs buzzed around my head and i was transported to a large golden gate that opened before behind it was a beautiful old man with a long white beard who stood there with his arms folded and a smirk on his he i i \n",
            "Original summary: eat this and you will find god \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-5506a7d4d421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Review:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original summary:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted summary:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_maxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-a5fc8c28b5f9>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Sample a token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 715\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    716\u001b[0m     return predict_loop(\n\u001b[1;32m    717\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2488\u001b[0m       \u001b[0mconverted_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2489\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_expected_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2490\u001b[0;31m         \u001b[0mconverted_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_scipy_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2491\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2492\u001b[0m       \u001b[0mx_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_convert_scipy_sparse_tensor\u001b[0;34m(value, expected_input)\u001b[0m\n\u001b[1;32m   3207\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mpossibly\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mconverted\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m   \"\"\"\n\u001b[0;32m-> 3209\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dense_tensor_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3211\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36misspmatrix\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1193\u001b[0m     \"\"\"Is x of a sparse matrix type?\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tocOcLTV7TI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}